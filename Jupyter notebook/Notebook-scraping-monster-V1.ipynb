{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_____Librairies importées\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2.extensions import parse_dsn\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[2]:\n",
    "\n",
    "\n",
    "\n",
    "##_____________Récuperer les urls de quatre metiers de la data \n",
    "\n",
    "Scrap_Monster = {\"mot_clef\":[], \"intitule_offre\": [], \"nom_entreprise\": [], \"lieu\": [], \"date\": [], \"lien\": [], 'latitude':[], 'longitude':[], 'description':[], 'langage1':[], 'langage2':[] }  \n",
    "\n",
    "list_clefs = [\"'data-analyst'\", \"'data-scientist'\", \"'developpeur-data'\", \"'data-ingenieur'\"]\n",
    "    \n",
    "for mot_clef in list_clefs:\n",
    "    url_sc_monster = f'https://www.monster.fr/emploi/recherche/?q={mot_clef}&where=Auvergne__2DRh__C3__B4ne__2DAlpes&cy=fr&stpage=1&page=9'\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "##___________Recuperation du code source html de site Monster lié à la data\n",
    "    r = rq.get(url_sc_monster, auth=('user', 'pass'))\n",
    "    r.status_code\n",
    "    r.headers['content-type']\n",
    "    soup = bs(r.text, 'html.parser')\n",
    "    #print(soup.prettify())\n",
    "\n",
    "\n",
    "    sc_intitule = soup.find_all(\"h2\", class_ = \"title\")\n",
    "    sc_nom_entreprise= soup.find_all(\"div\", class_ = \"company\")\n",
    "    sc_lien = soup.find_all(\"h2\", class_ = \"title\")\n",
    "    sc_lieu = soup.find_all(\"div\", class_ = \"location\")\n",
    "    sc_date = soup.find_all(\"div\", class_ = \"meta flex-col\")\n",
    "    sc_autre_lieu = soup.find_all(\"span\", class_ = \"mux-tooltip multi-loc-link\")\n",
    "    sc_coord =soup.find_all('a',{\"data-bypass\":\"true\"})\n",
    "\n",
    "\n",
    "    for i in range(len(soup.find_all(\"div\", {\"class\":\"summary\"}))-1):\n",
    "        Scrap_Monster[\"mot_clef\"].append(mot_clef)\n",
    "        Scrap_Monster[\"intitule_offre\"].append(sc_intitule[i].text.replace(\"\\n\", \"\").strip())        \n",
    "        Scrap_Monster[\"lien\"].append(sc_lien[i].find('a').get('href'))      \n",
    "        Scrap_Monster[\"nom_entreprise\"].append(sc_nom_entreprise[i].text.replace(\"\\n\", \" \").strip())      \n",
    "        Scrap_Monster[\"lieu\"].append(sc_lieu[i+1].text.replace(\"\\n\", \"\").strip().replace(\", Auvergne-Rhône-Alpes\", \" \"))\n",
    "        Scrap_Monster[\"date\"].append(sc_date[i].text.replace(\"\\n\", \"\").strip().replace(\"PostuléSauvegardée\", \" \").replace(\"Publiée \", \" \"))\n",
    "        Scrap_Monster['latitude'].append(str(sc_coord[i].get('data-m_impr_j_lat')))\n",
    "        Scrap_Monster['longitude'].append(str(sc_coord[i].get('data-m_impr_j_long')))\n",
    "    \n",
    "   \n",
    "#__________Recuperer la discription de chaque offre \n",
    "\n",
    "        url_offre = sc_lien[i].find('a').get('href')\n",
    "        r = rq.get(url_offre)\n",
    "        soupet = bs(r.text, 'html.parser')\n",
    "\n",
    "        sc_description_raw = soupet.find(\"div\", class_ = \"job-description\")\n",
    "    \n",
    "        if  sc_description_raw is None:\n",
    "    \n",
    "            Scrap_Monster[\"description\"].append(None)\n",
    "        else:\n",
    "            sc_description = sc_description_raw.text\n",
    "            Scrap_Monster[\"description\"].append(sc_description)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "#__________Regex pour recuperer les outils et les languages    \n",
    "        pattern1 = re.compile(r'(?P<sql>[Ss][Qq][Ll])')\n",
    "        pattern2 = re.compile(r'(?P<python>[Pp][Yy][Tt][Hh][Oo][Nn])')\n",
    "        match1 = re.search(pattern1,sc_description)\n",
    "        match2 = re.search(pattern2,sc_description)\n",
    "        if match1 is None:\n",
    "            Scrap_Monster[\"langage1\"].append(np.nan)    \n",
    "        else:\n",
    "            Scrap_Monster[\"langage1\"].append(match1.group())\n",
    "        \n",
    "        if match2 is None:\n",
    "            Scrap_Monster[\"langage2\"].append(np.nan)\n",
    "        else:   \n",
    "        \n",
    "            Scrap_Monster[\"langage2\"].append(match2.group())\n",
    "    \n",
    "\n",
    "        \n",
    "#___________Transformation du dictionnaire en datafram\n",
    "df = pd.DataFrame(Scrap_Monster)\n",
    "df1 = df.astype(object).replace('None', np.nan)\n",
    "#df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mot_clef</th>\n",
       "      <th>intitule_offre</th>\n",
       "      <th>nom_entreprise</th>\n",
       "      <th>lieu</th>\n",
       "      <th>date</th>\n",
       "      <th>lien</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>description</th>\n",
       "      <th>langage1</th>\n",
       "      <th>langage2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'data-analyst'</td>\n",
       "      <td>Data Financial Analyst H/F</td>\n",
       "      <td>Michael Page</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>aujourd'hui</td>\n",
       "      <td>https://offre-demploi.monster.fr/data-financia...</td>\n",
       "      <td>45.7674</td>\n",
       "      <td>4.83430000000001</td>\n",
       "      <td>DescriptionNotre client est un Groupe de capit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'data-analyst'</td>\n",
       "      <td>Business intelligence ou Data Analyst (H/F)</td>\n",
       "      <td>Innovallée</td>\n",
       "      <td>Meylan</td>\n",
       "      <td>il y a 2 jours</td>\n",
       "      <td>https://offre-demploi.monster.fr/business-inte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DescriptionTalents\\n \\n Business intelligence ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'data-analyst'</td>\n",
       "      <td>Stage - Data Analyst Junior - H/F</td>\n",
       "      <td>Photoweb</td>\n",
       "      <td>Saint-Egrève</td>\n",
       "      <td>il y a 7 jours</td>\n",
       "      <td>https://offre-demploi.monster.fr/stage-data-an...</td>\n",
       "      <td>45.2178</td>\n",
       "      <td>5.77959999999999</td>\n",
       "      <td>DescriptionEn tant que Data Analyst Junior, no...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'data-analyst'</td>\n",
       "      <td>Data Analyst F/H</td>\n",
       "      <td>AVANCI</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>il y a +30 jours</td>\n",
       "      <td>https://offre-demploi.monster.fr/data-analyst-...</td>\n",
       "      <td>45.2712</td>\n",
       "      <td>5.6782</td>\n",
       "      <td>DescriptionData Analyst F/H\\n \\n &gt;  &gt; DATA ANA...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'data-analyst'</td>\n",
       "      <td>Web Data Analyst confirmé H/F</td>\n",
       "      <td>Wizbii</td>\n",
       "      <td>Grenoble</td>\n",
       "      <td>il y a +30 jours</td>\n",
       "      <td>https://offre-demploi.monster.fr/web-data-anal...</td>\n",
       "      <td>45.7674</td>\n",
       "      <td>4.83430000000001</td>\n",
       "      <td>DescriptionBienvenue dans notre magnifique ave...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>'data-ingenieur'</td>\n",
       "      <td>SRE Engineer /Ops (H/F)</td>\n",
       "      <td>Coservit</td>\n",
       "      <td>Grenoble</td>\n",
       "      <td>il y a +30 jours</td>\n",
       "      <td>https://offre-demploi.monster.fr/sre-engineer-...</td>\n",
       "      <td>45.1808</td>\n",
       "      <td>5.697</td>\n",
       "      <td>DescriptionSRE Engineer /Ops\\n \\n PUBLISHED ON...</td>\n",
       "      <td>sql</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>'data-ingenieur'</td>\n",
       "      <td>Stage - Ingenieur Travaux Infrastructures Liné...</td>\n",
       "      <td>Ingérop</td>\n",
       "      <td>Grenoble</td>\n",
       "      <td>il y a +30 jours</td>\n",
       "      <td>https://offre-demploi.monster.fr/stage-ingenie...</td>\n",
       "      <td>45.7674</td>\n",
       "      <td>4.83430000000001</td>\n",
       "      <td>DescriptionOuvrir le sous-menu\\n \\n Fermer le ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>'data-ingenieur'</td>\n",
       "      <td>Ingénieur Système &amp; Réseau (H/F)</td>\n",
       "      <td>Rezopole</td>\n",
       "      <td>Caluire-et-Cuire</td>\n",
       "      <td>il y a 5 jours</td>\n",
       "      <td>https://offre-demploi.monster.fr/ingénieur-sys...</td>\n",
       "      <td>45.1942</td>\n",
       "      <td>5.73159999999999</td>\n",
       "      <td>DescriptionIngénieur Système &amp; Réseau (H/F) \\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>'data-ingenieur'</td>\n",
       "      <td>Ingénieur Systèmes et Réseaux - ★★★★★ (H/F)</td>\n",
       "      <td>Soluxan</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>il y a 13 jours</td>\n",
       "      <td>https://offre-demploi.monster.fr/ingénieur-sys...</td>\n",
       "      <td>45.1942</td>\n",
       "      <td>5.73159999999999</td>\n",
       "      <td>DescriptionPoste disponible en CDI ou Freelanc...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>'data-ingenieur'</td>\n",
       "      <td>Ingénieur Systèmes et Réseaux Lyon H/F - 139Vi...</td>\n",
       "      <td>Visiativ</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>il y a 15 jours</td>\n",
       "      <td>https://offre-demploi.monster.fr/ingénieur-sys...</td>\n",
       "      <td>45.7962</td>\n",
       "      <td>4.84229999999999</td>\n",
       "      <td>DescriptionIngénieur Systèmes et Réseaux Lyon ...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mot_clef                                     intitule_offre  \\\n",
       "0      'data-analyst'                         Data Financial Analyst H/F   \n",
       "1      'data-analyst'        Business intelligence ou Data Analyst (H/F)   \n",
       "2      'data-analyst'                  Stage - Data Analyst Junior - H/F   \n",
       "3      'data-analyst'                                   Data Analyst F/H   \n",
       "4      'data-analyst'                      Web Data Analyst confirmé H/F   \n",
       "..                ...                                                ...   \n",
       "313  'data-ingenieur'                            SRE Engineer /Ops (H/F)   \n",
       "314  'data-ingenieur'  Stage - Ingenieur Travaux Infrastructures Liné...   \n",
       "315  'data-ingenieur'                   Ingénieur Système & Réseau (H/F)   \n",
       "316  'data-ingenieur'        Ingénieur Systèmes et Réseaux - ★★★★★ (H/F)   \n",
       "317  'data-ingenieur'  Ingénieur Systèmes et Réseaux Lyon H/F - 139Vi...   \n",
       "\n",
       "    nom_entreprise               lieu               date  \\\n",
       "0     Michael Page              Lyon        aujourd'hui    \n",
       "1       Innovallée            Meylan     il y a 2 jours    \n",
       "2         Photoweb      Saint-Egrève     il y a 7 jours    \n",
       "3           AVANCI              Lyon   il y a +30 jours    \n",
       "4           Wizbii          Grenoble   il y a +30 jours    \n",
       "..             ...                ...                ...   \n",
       "313       Coservit          Grenoble   il y a +30 jours    \n",
       "314        Ingérop          Grenoble   il y a +30 jours    \n",
       "315       Rezopole  Caluire-et-Cuire     il y a 5 jours    \n",
       "316        Soluxan              Lyon    il y a 13 jours    \n",
       "317       Visiativ              Lyon    il y a 15 jours    \n",
       "\n",
       "                                                  lien latitude  \\\n",
       "0    https://offre-demploi.monster.fr/data-financia...  45.7674   \n",
       "1    https://offre-demploi.monster.fr/business-inte...      NaN   \n",
       "2    https://offre-demploi.monster.fr/stage-data-an...  45.2178   \n",
       "3    https://offre-demploi.monster.fr/data-analyst-...  45.2712   \n",
       "4    https://offre-demploi.monster.fr/web-data-anal...  45.7674   \n",
       "..                                                 ...      ...   \n",
       "313  https://offre-demploi.monster.fr/sre-engineer-...  45.1808   \n",
       "314  https://offre-demploi.monster.fr/stage-ingenie...  45.7674   \n",
       "315  https://offre-demploi.monster.fr/ingénieur-sys...  45.1942   \n",
       "316  https://offre-demploi.monster.fr/ingénieur-sys...  45.1942   \n",
       "317  https://offre-demploi.monster.fr/ingénieur-sys...  45.7962   \n",
       "\n",
       "            longitude                                        description  \\\n",
       "0    4.83430000000001  DescriptionNotre client est un Groupe de capit...   \n",
       "1                 NaN  DescriptionTalents\\n \\n Business intelligence ...   \n",
       "2    5.77959999999999  DescriptionEn tant que Data Analyst Junior, no...   \n",
       "3              5.6782  DescriptionData Analyst F/H\\n \\n >  > DATA ANA...   \n",
       "4    4.83430000000001  DescriptionBienvenue dans notre magnifique ave...   \n",
       "..                ...                                                ...   \n",
       "313             5.697  DescriptionSRE Engineer /Ops\\n \\n PUBLISHED ON...   \n",
       "314  4.83430000000001  DescriptionOuvrir le sous-menu\\n \\n Fermer le ...   \n",
       "315  5.73159999999999  DescriptionIngénieur Système & Réseau (H/F) \\n...   \n",
       "316  5.73159999999999  DescriptionPoste disponible en CDI ou Freelanc...   \n",
       "317  4.84229999999999  DescriptionIngénieur Systèmes et Réseaux Lyon ...   \n",
       "\n",
       "    langage1 langage2  \n",
       "0        NaN      NaN  \n",
       "1        NaN      NaN  \n",
       "2        SQL      NaN  \n",
       "3        SQL   Python  \n",
       "4        SQL      NaN  \n",
       "..       ...      ...  \n",
       "313      sql   Python  \n",
       "314      NaN      NaN  \n",
       "315      NaN      NaN  \n",
       "316      SQL      NaN  \n",
       "317      SQL      NaN  \n",
       "\n",
       "[318 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(df1.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__________Création d'un csv à partir du dataframe\n",
    "\n",
    "df1.to_csv(\"Scp_MONSTER.csv\", index =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 \n",
    "from psycopg2.extensions import parse_dsn \n",
    "import os\n",
    "import requests\n",
    "fname = 'Scp_MONSTER.csv'\n",
    "db_dsn = \"postgres://postgres:test@localhost:5432/decouverte\"\n",
    "db_args = parse_dsn(db_dsn)\n",
    "conn = psycopg2.connect(**db_args)\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(db_dsn)\n",
    "df1.to_sql('monster', engine, if_exists='replace', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A l'aide d'un requête SQL (en SQLite et PostgreSQL), vérifier les valeurs du nombre\n",
    "# total de lignes dans le fichier CSV ainsi que le nombre de valeurs manquantes dans\n",
    "# 2 colonnes du jeu de données\n",
    "#cursor = conn_postgre.cursor()\n",
    "conn = psycopg2.connect(**db_args)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT count(*) FROM monster;\")\n",
    "print(\"Nombre de lignes :\")\n",
    "print(cursor.fetchone()[0])\n",
    "cursor.execute(\"SELECT count(*)-count(latitude) FROM monster;\")\n",
    "print(\"Nombre de valeurs manquantes dans la colonne latitude :\")\n",
    "print(cursor.fetchone()[0])\n",
    "cursor.execute(\"SELECT count(*)-count(longitude) FROM monster;\")\n",
    "print(\"Nombre de valeurs manquantes dans la colonne longitude :\")\n",
    "print(cursor.fetchone()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_postgre = psycopg2.connect(**db_args)\n",
    "cursor = conn_postgre.cursor()\n",
    "for column in df.columns:\n",
    "    req = f\"SELECT round(cast(count(1)-count({column}) as NUMERIC)/count(1), 2)*100 FROM monster;\"\n",
    "    cursor.execute(req)\n",
    "    nb_missing = cursor.fetchone()[0]\n",
    "    if nb_missing>80:\n",
    "        print(f\"La colonne {column} contient {nb_missing}% de valeurs manquantes\".upper())\n",
    "    else:\n",
    "        print(f\"La colonne {column} contient {nb_missing}% de valeurs manquantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Scp_MONSTER.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un résumé des informations sur les données du dataframe à l'aide d'une méthode\n",
    "# de dataframe (nombre de lignes, nombres de valeurs présentes par colonne, types de valeurs...)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En python et en SQL, créer un nouveau dataframe (ou nouvelle table en SQL) qui ne contient\n",
    "# que les colonnes qui ont moins de 10% de valeurs manquantes\n",
    "\n",
    "# EN PYTHON\n",
    "columns_selected = []\n",
    "for column in df.columns:\n",
    "    nb_missing = round(df[column].isnull().sum() / df.shape[0], 2)*100\n",
    "    if nb_missing<30:\n",
    "        columns_selected.append(column)\n",
    "df_clean = df[columns_selected]\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pandas(df, max_missing):\n",
    "    columns_selected = []\n",
    "    for column in df.columns:\n",
    "        nb_missing = round(df[column].isnull().sum() / df.shape[0], 2)*100\n",
    "        if nb_missing<max_missing:\n",
    "            columns_selected.append(column)\n",
    "    df_clean = df[columns_selected]\n",
    "    df_clean.info()\n",
    "    return df_clean\n",
    "def clean_data(data_type=\"pandas\", df=None, max_missing=10, conn=None, table_name=\"data\"):\n",
    "    if data_type==\"pandas\":\n",
    "        return clean_pandas(df=df, max_missing=max_missing)\n",
    "    elif data_type==\"sql\":\n",
    "        clean_sql(max_missing=max_missing, conn=conn, table_name=table_name)\n",
    "    else:\n",
    "        print(f\"Le type de donnée '{data_type}' n'existe pas\")\n",
    "df_clean = clean_data(data_type=\"pandas\", df=df, max_missing=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"SELECT * FROM monster;\"\n",
    "df = pd.read_sql(sql_query, conn_postgre)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour les colonnes de catégories, afficher le nombre de valeurs par catégorie à l'aide de pandas\n",
    "cat_col = [\"mot_clef\",\"intitule_offre\", \"nom_entreprise\", \"lieu\", \"date\",\"lien\",\"latitude\",\"longitude\",\"langage1\",\"langage2\"]\n",
    "for col in cat_col:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le nombres de valeurs pour chacune des catégories de cette colonne\n",
    "#df['longitude'].value_counts()\n",
    "df['latitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['latitude'] == 'unknown', 'latitude'] = np.nan\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"latitude\"].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"latitude\"] = df_clean[\"latitude\"].fillna(df_clean[\"latitude\"].mode()[0])\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"longitude\"] = df_clean[\"longitude\"].fillna(df_clean[\"longitude\"].mean())\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.dropna(axis=0)\n",
    "df_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visu = pd.DataFrame(df)\n",
    "df_visu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import folium\n",
    "import pandas as pd\n",
    "from folium.plugins import MarkerCluster\n",
    "LAT_GRE = 45.188529\n",
    "LONG_GRE = 5.724524\n",
    "maps = folium.Map(location=[LAT_GRE, LONG_GRE],zoom_start=12)\n",
    "marker_cluster= MarkerCluster()\n",
    "for row in df_visu.itertuples():\n",
    "    try :   \n",
    "        folium.Marker(location=[row.latitude, row.longitude], popup=row.intitule_offre).add_to(marker_cluster)\n",
    "    except :\n",
    "        marker_cluster.add_to(maps)\n",
    "        #print(row)\n",
    "# Afficher un périmètre de rayon 15km autour du centre de la carte\n",
    "folium.Circle(\n",
    "    radius= 15000,\n",
    "    location= [LAT_GRE, LONG_GRE],\n",
    "    color= \"crimson\",\n",
    "    fill=False,\n",
    ").add_to(maps)\n",
    "\n",
    "maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
